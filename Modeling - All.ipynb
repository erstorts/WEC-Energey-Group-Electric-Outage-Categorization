{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "#AWS\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.tuner import HyperparameterTuner, ContinuousParameter, IntegerParameter, CategoricalParameter\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score, precision_score, fbeta_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://distribution-reliability-nlp/modeling\n"
     ]
    }
   ],
   "source": [
    "#get information for later use\n",
    "#role\n",
    "role = get_execution_role()\n",
    "#session\n",
    "sess = sagemaker.Session()\n",
    "#sagemaker region\n",
    "region = sess.boto_session.region_name\n",
    "#account number\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "#s3 bucket name\n",
    "bucket = 'distribution-reliability-nlp'\n",
    "#create a sagemaker client object\n",
    "smclient = boto3.client(service_name='sagemaker')\n",
    "#model folder name\n",
    "model_location = 's3://{}/modeling'.format(bucket)\n",
    "print(model_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volt_D</th>\n",
       "      <th>Volt_E</th>\n",
       "      <th>Volt_F</th>\n",
       "      <th>Volt_H</th>\n",
       "      <th>Volt_J</th>\n",
       "      <th>Volt_M</th>\n",
       "      <th>Volt_R</th>\n",
       "      <th>Volt_SD</th>\n",
       "      <th>Volt_TV</th>\n",
       "      <th>Volt_US</th>\n",
       "      <th>...</th>\n",
       "      <th>year_2011</th>\n",
       "      <th>year_2012</th>\n",
       "      <th>year_2013</th>\n",
       "      <th>year_2014</th>\n",
       "      <th>year_2015</th>\n",
       "      <th>year_2016</th>\n",
       "      <th>year_2017</th>\n",
       "      <th>year_2018</th>\n",
       "      <th>outage category</th>\n",
       "      <th>outage subcategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>Conductor/Cable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Vegetation</td>\n",
       "      <td>Out Clearance Zone (ROW)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>Conductor/Cable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 788 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Volt_D  Volt_E  Volt_F  Volt_H  Volt_J  Volt_M  Volt_R  Volt_SD  Volt_TV  \\\n",
       "0       0       0       0       0       0       0       0        0        0   \n",
       "1       0       0       0       0       0       0       0        1        0   \n",
       "2       0       0       0       0       0       1       0        0        0   \n",
       "3       0       0       0       0       0       0       0        0        0   \n",
       "4       0       0       0       0       0       0       0        1        0   \n",
       "\n",
       "   Volt_US  ...  year_2011  year_2012  year_2013  year_2014  year_2015  \\\n",
       "0        0  ...          0          0          0          0          0   \n",
       "1        0  ...          0          0          0          0          0   \n",
       "2        0  ...          0          0          0          0          0   \n",
       "3        0  ...          0          0          0          0          0   \n",
       "4        0  ...          0          0          0          0          0   \n",
       "\n",
       "   year_2016  year_2017  year_2018  outage category        outage subcategory  \n",
       "0          0          0          0        Equipment                       NaN  \n",
       "1          0          0          0        Equipment           Conductor/Cable  \n",
       "2          0          0          0       Vegetation  Out Clearance Zone (ROW)  \n",
       "3          0          0          0        Equipment           Conductor/Cable  \n",
       "4          0          0          0        Equipment                       NaN  \n",
       "\n",
       "[5 rows x 788 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "we_outage = pd.read_csv('We_Cleaned.csv')\n",
    "we_outage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outage category</th>\n",
       "      <th>outage subcategory</th>\n",
       "      <th>Mobile Data Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Equipment</td>\n",
       "      <td>Conductor/Cable</td>\n",
       "      <td>one leg of urd is dead customer said we can f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vegetation</td>\n",
       "      <td>Out Clearance Zone (ROW)</td>\n",
       "      <td>removed tree from line nearpole63 1688 and cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Equipment</td>\n",
       "      <td>Conductor/Cable</td>\n",
       "      <td>repaired bad primary urd cables cable repaire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Equipment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bad connector on cust serv pole conn replaced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Equipment</td>\n",
       "      <td>Simple Interrupting Device</td>\n",
       "      <td>replaced broken cutout and installed wlp taq ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  outage category          outage subcategory  \\\n",
       "0       Equipment             Conductor/Cable   \n",
       "1      Vegetation    Out Clearance Zone (ROW)   \n",
       "2       Equipment             Conductor/Cable   \n",
       "3       Equipment                         NaN   \n",
       "4       Equipment  Simple Interrupting Device   \n",
       "\n",
       "                                 Mobile Data Remarks  \n",
       "0   one leg of urd is dead customer said we can f...  \n",
       "1   removed tree from line nearpole63 1688 and cl...  \n",
       "2   repaired bad primary urd cables cable repaire...  \n",
       "3   bad connector on cust serv pole conn replaced...  \n",
       "4   replaced broken cutout and installed wlp taq ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import text data\n",
    "outage = pd.read_csv('We_WPS_comments_categories.csv')\n",
    "outage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outage category</th>\n",
       "      <th>Volt_D</th>\n",
       "      <th>Volt_E</th>\n",
       "      <th>Volt_F</th>\n",
       "      <th>Volt_H</th>\n",
       "      <th>Volt_J</th>\n",
       "      <th>Volt_M</th>\n",
       "      <th>Volt_R</th>\n",
       "      <th>Volt_SD</th>\n",
       "      <th>Volt_TV</th>\n",
       "      <th>...</th>\n",
       "      <th>week_9</th>\n",
       "      <th>year_2010</th>\n",
       "      <th>year_2011</th>\n",
       "      <th>year_2012</th>\n",
       "      <th>year_2013</th>\n",
       "      <th>year_2014</th>\n",
       "      <th>year_2015</th>\n",
       "      <th>year_2016</th>\n",
       "      <th>year_2017</th>\n",
       "      <th>year_2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 787 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   outage category  Volt_D  Volt_E  Volt_F  Volt_H  Volt_J  Volt_M  Volt_R  \\\n",
       "0                0       0       0       0       0       0       0       0   \n",
       "1                0       0       0       0       0       0       0       0   \n",
       "2                1       0       0       0       0       0       1       0   \n",
       "3                0       0       0       0       0       0       0       0   \n",
       "4                0       0       0       0       0       0       0       0   \n",
       "\n",
       "   Volt_SD  Volt_TV  ...  week_9  year_2010  year_2011  year_2012  year_2013  \\\n",
       "0        0        0  ...       0          1          0          0          0   \n",
       "1        1        0  ...       0          1          0          0          0   \n",
       "2        0        0  ...       0          1          0          0          0   \n",
       "3        0        0  ...       0          1          0          0          0   \n",
       "4        1        0  ...       0          1          0          0          0   \n",
       "\n",
       "   year_2014  year_2015  year_2016  year_2017  year_2018  \n",
       "0          0          0          0          0          0  \n",
       "1          0          0          0          0          0  \n",
       "2          0          0          0          0          0  \n",
       "3          0          0          0          0          0  \n",
       "4          0          0          0          0          0  \n",
       "\n",
       "[5 rows x 787 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split features and target\n",
    "we_outage_limited = we_outage.drop(['outage subcategory'], axis=1)\n",
    "we_outage_limited['outage category'] = pd.factorize(we_outage_limited['outage category'])[0]\n",
    "we_outage_limited = we_outage_limited[['outage category']+list(we_outage_limited)[:-1]]\n",
    "we_outage_limited.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outage category</th>\n",
       "      <th>outage subcategory</th>\n",
       "      <th>Mobile Data Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Conductor/Cable</td>\n",
       "      <td>one leg of urd is dead customer said we can f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Out Clearance Zone (ROW)</td>\n",
       "      <td>removed tree from line nearpole63 1688 and cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Conductor/Cable</td>\n",
       "      <td>repaired bad primary urd cables cable repaire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bad connector on cust serv pole conn replaced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Simple Interrupting Device</td>\n",
       "      <td>replaced broken cutout and installed wlp taq ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outage category          outage subcategory  \\\n",
       "0                0             Conductor/Cable   \n",
       "1                1    Out Clearance Zone (ROW)   \n",
       "2                0             Conductor/Cable   \n",
       "3                0                         NaN   \n",
       "4                0  Simple Interrupting Device   \n",
       "\n",
       "                                 Mobile Data Remarks  \n",
       "0   one leg of urd is dead customer said we can f...  \n",
       "1   removed tree from line nearpole63 1688 and cl...  \n",
       "2   repaired bad primary urd cables cable repaire...  \n",
       "3   bad connector on cust serv pole conn replaced...  \n",
       "4   replaced broken cutout and installed wlp taq ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seperating out unknown causes\n",
    "all_unknowns = outage[outage['outage category'] == 'Unknown']\n",
    "#save off unknowns\n",
    "#all_unknowns.to_csv('Unknown Outcomes.csv')\n",
    "#remove unknowns and not reporteable\n",
    "outage = outage[outage['outage category'] != 'Unknown']\n",
    "outage = outage[outage['outage category'] != 'Not Reportable']\n",
    "\n",
    "#convert target to numeric\n",
    "outage['outage category'] = pd.factorize(outage['outage category'])[0]\n",
    "outage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'we_outage_limited' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-81fbae43dbae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train, test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwe_outage_limited\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'we_outage_limited' is not defined"
     ]
    }
   ],
   "source": [
    "#train, test split\n",
    "train_data, test_data = train_test_split(we_outage_limited, test_size=0.1, random_state=42)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139826, 3)\n",
      "(139785, 3)\n"
     ]
    }
   ],
   "source": [
    "print(outage.shape)\n",
    "outage = outage[outage['Mobile Data Remarks'].notna()]\n",
    "print(outage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(outage, test_size=0.1, random_state=42)\n",
    "#create count object\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "#Transform the training data using only the 'text' column values\n",
    "X_train = count_vectorizer.fit_transform(train_data['Mobile Data Remarks'])\n",
    "\n",
    "#Transform the test data using only the 'text' column values\n",
    "X_test = count_vectorizer.transform(test_data['Mobile Data Remarks'])\n",
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_data, tfidf_test_data = train_test_split(outage, test_size=0.1, random_state=42)\n",
    "#create count object\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "#Transform the training data using only the 'text' column values\n",
    "tfidf_X_train = tfidf_vectorizer.fit_transform(tfidf_train_data['Mobile Data Remarks'])\n",
    "\n",
    "#Transform the test data using only the 'text' column values\n",
    "tfidf_X_test = tfidf_vectorizer.transform(tfidf_test_data['Mobile Data Remarks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_train_data, hash_test_data = train_test_split(outage, test_size=0.1, random_state=42)\n",
    "#create count object\n",
    "hash_vectorizer = HashingVectorizer(stop_words='english')\n",
    "\n",
    "#Transform the training data using only the 'text' column values\n",
    "hash_X_train = hash_vectorizer.fit_transform(hash_train_data['Mobile Data Remarks'])\n",
    "\n",
    "#Transform the test data using only the 'text' column values\n",
    "hash_X_test = hash_vectorizer.transform(hash_test_data['Mobile Data Remarks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(count_vectorizer, open('count-vectorizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.to_csv('decoder.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50083     4\n",
       "37297     1\n",
       "125019    4\n",
       "5111      3\n",
       "77071     1\n",
       "Name: outage category, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_data['outage category']\n",
    "y_test = test_data['outage category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_y_train = tfidf_train_data['outage category']\n",
    "tfidf_y_test = tfidf_test_data['outage category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_y_train = hash_train_data['outage category']\n",
    "hash_y_test = hash_test_data['outage category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapt test data to batch transform restrictions for later\n",
    "test_data = test_data.head(1000)\n",
    "test_data_chopped = test_data.drop(['outage category'], axis=1)\n",
    "test_data_chopped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to csv\n",
    "train_data.to_csv('Non-Text_train.csv', header=False, index=False)\n",
    "test_data_chopped.to_csv('Non-Text_test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to csv\n",
    "scipy.sparse.save_npz('train.npz', X_train)\n",
    "y_train.to_csv('train_target.csv', header=False, index=False)\n",
    "scipy.sparse.save_npz('test.npz', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to csv\n",
    "scipy.sparse.save_npz('tfidf_train.npz', tfidf_X_train)\n",
    "tfidf_y_train.to_csv('tfidf_train_target.csv', header=False, index=False)\n",
    "scipy.sparse.save_npz('tfidf_test.npz', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to csv\n",
    "scipy.sparse.save_npz('hash_train.npz', X_train)\n",
    "hash_y_train.to_csv('hash_train_target.csv', header=False, index=False)\n",
    "scipy.sparse.save_npz('hash_test.npz', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send data to S3. SageMaker will take training data from s3\n",
    "trainpath = sess.upload_data(\n",
    "    path='Non-Text_train.csv', bucket=bucket,\n",
    "    key_prefix='sagemaker/data')\n",
    "\n",
    "testpath = sess.upload_data(\n",
    "    path='Non-Text_test.csv', bucket=bucket,\n",
    "    key_prefix='sagemaker/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send data to S3. SageMaker will take training data from s3\n",
    "train_path = sess.upload_data(\n",
    "    path='train.npz', bucket=bucket,\n",
    "    key_prefix='sagemaker/data')\n",
    "\n",
    "train_target_path = sess.upload_data(\n",
    "    path='train_target.csv', bucket=bucket,\n",
    "    key_prefix='sagemaker/data')\n",
    "\n",
    "test_path = sess.upload_data(\n",
    "    path='test.npz', bucket=bucket,\n",
    "    key_prefix='sagemaker/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send data to S3. SageMaker will take training data from s3\n",
    "train_path = sess.upload_data(\n",
    "    path='tfidf_train.npz', bucket=bucket,\n",
    "    key_prefix='sagemaker/data')\n",
    "\n",
    "train_target_path = sess.upload_data(\n",
    "    path='tfidf_train_target.csv', bucket=bucket,\n",
    "    key_prefix='sagemaker/data')\n",
    "\n",
    "test_path = sess.upload_data(\n",
    "    path='tfidf_test.npz', bucket=bucket,\n",
    "    key_prefix='sagemaker/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send data to S3. SageMaker will take training data from s3\n",
    "train_path = sess.upload_data(\n",
    "    path='hash_train.npz', bucket=bucket,\n",
    "    key_prefix='sagemaker/data')\n",
    "\n",
    "train_target_path = sess.upload_data(\n",
    "    path='hash_train_target.csv', bucket=bucket,\n",
    "    key_prefix='sagemaker/data')\n",
    "\n",
    "test_path = sess.upload_data(\n",
    "    path='hash_test.npz', bucket=bucket,\n",
    "    key_prefix='sagemaker/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimator(algorithm_name, algorithm_type, account, sess, role):\n",
    "    '''\n",
    "    This function takes a model name, account number, sagemaker session, and role to return the model estimator\n",
    "    '''\n",
    "    if algorithm_type == 'Classification':\n",
    "        if algorithm_name == 'Neural Network':\n",
    "            algorithm_name_type = 'sagemaker-basic-neural-network-classification'\n",
    "        elif algorithm_name == 'Decision Tree':\n",
    "            algorithm_name_type = 'sagemaker-decision-tree-classification'\n",
    "        elif algorithm_name == 'Gradient Boosting':\n",
    "            algorithm_name_type = 'sagemaker-gradient-boosting-classification'\n",
    "        elif algorithm_name == 'K-Nearest Neighbors':\n",
    "            algorithm_name_type = 'sagemaker-k-nearest-neighbors-classification'\n",
    "        elif algorithm_name == 'Logitstic Regression':\n",
    "            algorithm_name_type = 'sagemaker-logistic-regression'\n",
    "        elif algorithm_name == 'Naive Bayes':\n",
    "            algorithm_name_type = 'sagemaker-naive-bayes-multinomial'\n",
    "        elif algorithm_name == 'Random Forest':\n",
    "            algorithm_name_type = 'sagemaker-random-forest-classification'\n",
    "        elif algorithm_name == 'Stochastic Gradient Descent':\n",
    "            algorithm_name_type = 'sagemaker-stochastic-gradient-descent-classification'\n",
    "        elif algorithm_name == 'Support Vector Machine':\n",
    "            algorithm_name_type = 'sagemaker-support-vector-classification'\n",
    "        else:\n",
    "            return print('ModelTypeError: The model entered is not available. Please select a new model type.')\n",
    "    elif algorithm_type == 'Regression':\n",
    "        if algorithm_name == 'Neural Network':\n",
    "            algorithm_name_type = 'sagemaker-basic-neural-network-regression'\n",
    "        elif algorithm_name == 'Decision Tree':\n",
    "            algorithm_name_type = 'sagemaker-decision-tree-regression'\n",
    "        elif algorithm_name == 'Gradient Boosting':\n",
    "            algorithm_name_type = 'sagemaker-gradient-boosting-regression'\n",
    "        elif algorithm_name == 'K-Nearest Neighbors':\n",
    "            algorithm_name_type = 'sagemaker-k-nearest-neighbors-regression'\n",
    "        elif algorithm_name == 'Random Forest':\n",
    "            algorithm_name_type = 'sagemaker-random-forest-regression'\n",
    "        elif algorithm_name == 'Stochastic Gradient Descent':\n",
    "            algorithm_name_type = 'sagemaker-stochastic-gradient-descent-regression'\n",
    "        elif algorithm_name == 'Support Vector Machine':\n",
    "            algorithm_name_type = 'sagemaker-support-vector-regression'\n",
    "        elif algorithm_name == 'Lasso Regression':\n",
    "            algorithm_name_type = 'sagemaker-lasso-regression'\n",
    "        elif algorithm_name == 'Linear Regression':\n",
    "            algorithm_name_type = 'sagemaker-linear-regression'\n",
    "        elif algorithm_name == 'Ridge Regression':\n",
    "            algorithm_name_type = 'sagemaker-ridge-regression'    \n",
    "        else:\n",
    "            return print('ModelTypeError: The model entered is not available. Please select a new model type.')\n",
    "\n",
    "    #get docker image name in ECR\n",
    "    image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, algorithm_name_type)\n",
    "\n",
    "    #update where the model will be stored\n",
    "    updated_model_location = model_location + '/' + algorithm_name\n",
    "\n",
    "    #create estimator with the image selected\n",
    "    est = Estimator(image_name=image,\n",
    "                     role=role, \n",
    "                     train_instance_count=1, \n",
    "                     train_instance_type ='ml.c5.18xlarge',\n",
    "                     output_path=updated_model_location,\n",
    "                     sagemaker_session=sess,\n",
    "                     subnets=['subnet-535e1629', 'subnet-28756740', 'subnet-2253e36e'],\n",
    "                     security_group_ids=['sg-3168f952'])\n",
    "    #https://sagemaker.readthedocs.io/en/stable/overview.html#secure-training-and-inference-with-vpc\n",
    "    #https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_turner(algorithm_name, algorithm_type, data_type, eval_metric, eval_direction, estimator):\n",
    "    '''\n",
    "    this function takes in a model, it's type and the sagemaker estimator and returns the hyperparameter turner\n",
    "    with the full hyperparamerter ranges.\n",
    "    '''\n",
    "\n",
    "    #ContinuousParameter, IntegerParameter, CategoricalParameter\n",
    "    \n",
    "    #get hyperparmeter ranges\n",
    "    if algorithm_name == 'Neural Network':\n",
    "        hyperparameter_ranges = {'hidden_layer_sizes': IntegerParameter(2, 250),\n",
    "                                'activation': CategoricalParameter(['identity', 'logistic', 'tanh', 'relu']),\n",
    "                                'solver': CategoricalParameter(['lbfgs', 'sgd', 'adam']),\n",
    "                                'alpha': ContinuousParameter(0.0001, 0.1),\n",
    "                                'batch_size': IntegerParameter(100, 1000),\n",
    "                                'learning_rate': CategoricalParameter(['constant', 'invscaling', 'adaptive']),\n",
    "                                'learning_rate_init' : ContinuousParameter(0.0001, 0.1),\n",
    "                                'power_t': ContinuousParameter(0.1, 0.8),\n",
    "                                'max_iter': IntegerParameter(100, 250),\n",
    "                                'beta_1': ContinuousParameter(0.1, 0.9),\n",
    "                                'beta_2': ContinuousParameter(0.1, 0.999)}\n",
    "\n",
    "    elif algorithm_name == 'Decision Tree':\n",
    "        hyperparameter_ranges = {'criterion': CategoricalParameter(['gini', 'entropy']),\n",
    "                                 'splitter': CategoricalParameter(['best', 'random']),\n",
    "                                'max_depth': IntegerParameter(10, 100),\n",
    "                                'min_samples_split': IntegerParameter(2, 100),\n",
    "                                'min_samples_leaf': IntegerParameter(1, 100),\n",
    "                                'min_weight_fraction_leaf': ContinuousParameter(0, .5),\n",
    "                                'max_features' : IntegerParameter(1, 437),\n",
    "                                'max_leaf_nodes': IntegerParameter(2, 100),\n",
    "                                'min_impurity_decrease': ContinuousParameter(0, .25)}\n",
    "        \n",
    "    elif algorithm_name == 'Random Forest':\n",
    "        hyperparameter_ranges = {'n_estimators': IntegerParameter(250, 1000),\n",
    "                                'criterion': CategoricalParameter(['gini', 'entropy']),\n",
    "                                #'max_depth': IntegerParameter(10, 100),\n",
    "                                #'min_samples_split': IntegerParameter(2, 100),\n",
    "                                #'min_samples_leaf': IntegerParameter(1, 100),\n",
    "                                #'min_weight_fraction_leaf': ContinuousParameter(0, .5),\n",
    "                                #'max_features' : IntegerParameter(1, 437),\n",
    "                                #'max_leaf_nodes': IntegerParameter(2, 100),\n",
    "                                #'min_impurity_decrease': ContinuousParameter(0, .25),\n",
    "                                'bootstrap': CategoricalParameter([True, False])}    \n",
    "        \n",
    "    elif algorithm_name == 'Gradient Boosting':\n",
    "        hyperparameter_ranges = {'learning_rate': ContinuousParameter(0.001, .2),\n",
    "                                'n_estimators': IntegerParameter(250, 1000),\n",
    "                                'subsample': ContinuousParameter(.1, 1.0),\n",
    "                                'criterion': CategoricalParameter(['friedman_mse', 'mse', 'mae']),\n",
    "                                'max_depth': IntegerParameter(10, 100),\n",
    "                                'min_samples_split': IntegerParameter(2, 100),\n",
    "                                'min_samples_leaf': IntegerParameter(1, 100),\n",
    "                                'min_weight_fraction_leaf': ContinuousParameter(0, .5),\n",
    "                                'max_features' : IntegerParameter(1, 437),\n",
    "                                'max_leaf_nodes': IntegerParameter(2, 100),\n",
    "                                'min_impurity_decrease': ContinuousParameter(0, 0.25)\n",
    "                                }       \n",
    "        \n",
    "    elif algorithm_name == 'K-Nearest Neighbors':\n",
    "        hyperparameter_ranges = {'n_neighbors': IntegerParameter(3, 250),\n",
    "                                'weights': CategoricalParameter(['uniform', 'distance']),\n",
    "                                'algorithm': CategoricalParameter(['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
    "                                'leaf_size': IntegerParameter(10, 50),\n",
    "                                'p': IntegerParameter(0, 5)}  \n",
    "        \n",
    "    elif algorithm_name == 'Logitstic Regression':\n",
    "        hyperparameter_ranges = {'C': ContinuousParameter(0.1, 1.0),\n",
    "                                'multi_class': CategoricalParameter(['multinomial', 'auto']),\n",
    "                                'solver': CategoricalParameter(['newton-cg', 'sag', 'saga', 'lbfgs'])}\n",
    "        \n",
    "    elif algorithm_name == 'Naive Bayes':\n",
    "        hyperparameter_ranges = {'alpha': ContinuousParameter(0, 1.0),\n",
    "                                 'fit_prior': CategoricalParameter([True, False])}    \n",
    "\n",
    "    elif algorithm_name == 'Stochastic Gradient Descent':\n",
    "        hyperparameter_ranges = {'loss': CategoricalParameter(['hinge', 'log', 'modified_huber', 'squared_hinge',\n",
    "                                                              'perceptron']),\n",
    "                                'penalty': CategoricalParameter(['none', 'l2', 'l1', 'elasticnet']),\n",
    "                                'alpha': ContinuousParameter(0.0001, 0.01),\n",
    "                                'l1_ratio': ContinuousParameter(0.01, 1.0),\n",
    "                                'learning_rate': CategoricalParameter(['constant', 'optimal', 'invscaling', 'adaptive']),\n",
    "                                'eta0': ContinuousParameter(0.0, 0.1),\n",
    "                                'power_t': ContinuousParameter(0.1, 1.0)}    \n",
    "        \n",
    "    elif algorithm_name == 'Support Vector Machine':\n",
    "        hyperparameter_ranges = {'C': ContinuousParameter(0.1, 1.0),\n",
    "                                'kernel': CategoricalParameter(['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']),\n",
    "                                'degree': IntegerParameter(1, 5),\n",
    "                                'gamma': IntegerParameter(1, 5),\n",
    "                                'shrinking': CategoricalParameter([True, False]),\n",
    "                                'probability': CategoricalParameter([True, False]),\n",
    "                                'decision_function_shape': CategoricalParameter(['ovr', 'ovo'])}    \n",
    "    \n",
    "    #add the data type to the hyperparamter dict\n",
    "    if data_type == 'text':\n",
    "        hyperparameter_ranges['data_type'] = CategoricalParameter(['text', 'word'])\n",
    "    else:\n",
    "        hyperparameter_ranges['data_type'] = CategoricalParameter(['numeric', 'numbers'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #create metrics definitions\n",
    "    if eval_metric == 'F1-Score':\n",
    "        metric_defs = [{'Name': 'F1-Score',\n",
    "                        'Regex': \"F1-Score: ([0-9.]+).*$\"}]\n",
    "    elif eval_metric == 'Accuracy':\n",
    "        metric_defs = [{'Name': 'Accuracy',\n",
    "                        'Regex': \"Accuracy: ([0-9.]+).*$\"}]\n",
    "    elif eval_metric == 'Recall':\n",
    "        metric_defs = [{'Name': 'Recall',\n",
    "                        'Regex': \"Recall: ([0-9.]+).*$\"}]\n",
    "    elif eval_metric == 'Precision':\n",
    "        metric_defs = [{'Name': 'Precision',\n",
    "                        'Regex': \"Precision: ([0-9.]+).*$\"}]        \n",
    "    \n",
    "    \n",
    "    #make name for tuning job\n",
    "    tuning_name = algorithm_name.replace(' ', '-') + '-' + algorithm_type\n",
    "    \n",
    "    #set up hyperparamater turner\n",
    "    tuner = HyperparameterTuner(estimator=estimator,\n",
    "                                hyperparameter_ranges=hyperparameter_ranges,\n",
    "                                base_tuning_job_name=tuning_name,\n",
    "                                objective_type=eval_direction,\n",
    "                                objective_metric_name=eval_metric,\n",
    "                                metric_definitions=metric_defs, \n",
    "                                max_jobs=10)\n",
    "    \n",
    "    return tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Random Forest']\n"
     ]
    }
   ],
   "source": [
    "# all model options\n",
    "algorithms_1 = [#'K-Nearest Neighbors', \n",
    "                #'Naive Bayes', \n",
    "                #'Support Vector Machine' \n",
    "                #'Logitstic Regression'\n",
    "                #'Decision Tree'\n",
    "]\n",
    "algorithms_2 = [#'Stochastic Gradient Descent'\n",
    "                'Random Forest'\n",
    "                #'Gradient Boosting',\n",
    "                 #'Neural Network'\n",
    "]\n",
    "\n",
    "algorithms = algorithms_1 + algorithms_2\n",
    "print(algorithms)\n",
    "algorithm_type = 'Classification'\n",
    "eval_metric = 'Accuracy'\n",
    "eval_direction = 'Maximize'\n",
    "data_type = 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model Started Training.\n"
     ]
    }
   ],
   "source": [
    "for algorithm in algorithms:\n",
    "    print(algorithm)\n",
    "    #get estimater\n",
    "    est = get_estimator(algorithm, algorithm_type, account, sess, role)\n",
    "    #get hyper tuner\n",
    "    tuner = get_turner(algorithm_name=algorithm, \n",
    "                       algorithm_type=algorithm_type,\n",
    "                       data_type=data_type,\n",
    "                       eval_metric=eval_metric, \n",
    "                       eval_direction=eval_direction,\n",
    "                       estimator=est)\n",
    "    #start training\n",
    "    tuner.fit({'training': train_path,\n",
    "               'target': train_target_path},\n",
    "               wait=False)\n",
    "    print('Model Started Training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search the training job by Amazon S3 location of model artifacts\n",
    "search_params={\n",
    "   \"MaxResults\": 100,\n",
    "   \"Resource\": \"TrainingJob\",\n",
    "   \"SearchExpression\": { \n",
    "      \"Filters\": [ \n",
    "         { \n",
    "            \"Name\": \"InputDataConfig.DataSource.S3DataSource.S3Uri\",\n",
    "            \"Operator\": \"Contains\",\n",
    "             \n",
    "             # set this to have a word that is in your bucket name\n",
    "            \"Value\": '{}'.format(bucket)\n",
    "         },\n",
    "        { \n",
    "            \"Name\": \"TrainingJobStatus\",\n",
    "            \"Operator\": \"Equals\",\n",
    "            \"Value\": 'Completed'\n",
    "         }, \n",
    "    ],\n",
    "     \n",
    "   },\n",
    "    \n",
    "    \"SortBy\": \"LastModifiedTime\",\n",
    "    \"SortOrder\": \"Descending\"\n",
    "}\n",
    "results = smclient.search(**search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#look a validation results\n",
    "images = []\n",
    "scores = []\n",
    "hypers = []\n",
    "models = []\n",
    "for each in results['Results']:\n",
    "    try:\n",
    "        if each['TrainingJob']['FinalMetricDataList'][0]['MetricName'] == eval_metric:\n",
    "            images.append(each['TrainingJob']['AlgorithmSpecification']['TrainingImage'].split('/')[1].split(':')[0][10:])\n",
    "            scores.append(each['TrainingJob']['FinalMetricDataList'][0]['Value'])\n",
    "            hypers.append(each['TrainingJob']['HyperParameters'])\n",
    "            \n",
    "        #find job name\n",
    "        job_name = each['TrainingJob']['TrainingJobName']\n",
    "        #find model artifact\n",
    "        artifact = each['TrainingJob']['ModelArtifacts']['S3ModelArtifacts']\n",
    "        # get training image\n",
    "        image =  each['TrainingJob']['AlgorithmSpecification']['TrainingImage']\n",
    "        #make a sagemaker model\n",
    "        m = Model(artifact, image, role = role, sagemaker_session = sess, name = job_name)\n",
    "        #append the sagemaker model to the models list\n",
    "        models.append(m)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Metric Results</th>\n",
       "      <th>HyperParameters</th>\n",
       "      <th>Actual Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic-regression</td>\n",
       "      <td>0.826418</td>\n",
       "      <td>{'C': '0.865280262065544', '_tuning_objective_...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2a89ec75c0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stochastic-gradient-descent-classification</td>\n",
       "      <td>0.826418</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'alph...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7dd68&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic-regression</td>\n",
       "      <td>0.826339</td>\n",
       "      <td>{'C': '0.9995955195233935', '_tuning_objective...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7d048&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logistic-regression</td>\n",
       "      <td>0.826339</td>\n",
       "      <td>{'C': '1.0', '_tuning_objective_metric': 'Accu...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2a8a488908&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logistic-regression</td>\n",
       "      <td>0.826339</td>\n",
       "      <td>{'C': '0.8778731048356974', '_tuning_objective...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2a8a488e10&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logistic-regression</td>\n",
       "      <td>0.826339</td>\n",
       "      <td>{'C': '0.8682699554216349', '_tuning_objective...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7d978&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>logistic-regression</td>\n",
       "      <td>0.826339</td>\n",
       "      <td>{'C': '0.9199331634294474', '_tuning_objective...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2a89ec7320&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>basic-neural-network-classification</td>\n",
       "      <td>0.826259</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'acti...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2a89851cf8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>logistic-regression</td>\n",
       "      <td>0.826259</td>\n",
       "      <td>{'C': '0.9105947845231974', '_tuning_objective...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7d630&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>logistic-regression</td>\n",
       "      <td>0.826101</td>\n",
       "      <td>{'C': '0.9741506927263224', '_tuning_objective...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2a8a488748&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>logistic-regression</td>\n",
       "      <td>0.826101</td>\n",
       "      <td>{'C': '0.9782705657731974', '_tuning_objective...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2a8a4887f0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>logistic-regression</td>\n",
       "      <td>0.826021</td>\n",
       "      <td>{'C': '0.9370169036638224', '_tuning_objective...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2a89ec7a90&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>stochastic-gradient-descent-classification</td>\n",
       "      <td>0.826021</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'alph...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7deb8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>logistic-regression</td>\n",
       "      <td>0.826021</td>\n",
       "      <td>{'C': '0.9427297942888224', '_tuning_objective...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2a8a4884a8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>logistic-regression</td>\n",
       "      <td>0.825942</td>\n",
       "      <td>{'C': '0.7242842376481974', '_tuning_objective...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2a8a4883c8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stochastic-gradient-descent-classification</td>\n",
       "      <td>0.825625</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'alph...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7de80&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>stochastic-gradient-descent-classification</td>\n",
       "      <td>0.825625</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'alph...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7d860&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>basic-neural-network-classification</td>\n",
       "      <td>0.825228</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'acti...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2a89851e48&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>logistic-regression</td>\n",
       "      <td>0.823562</td>\n",
       "      <td>{'C': '0.36073785092944743', '_tuning_objectiv...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7d5f8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>logistic-regression</td>\n",
       "      <td>0.823403</td>\n",
       "      <td>{'C': '0.31521819760913494', '_tuning_objectiv...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2a8a488470&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>basic-neural-network-classification</td>\n",
       "      <td>0.823007</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'acti...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2a8a488c50&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>stochastic-gradient-descent-classification</td>\n",
       "      <td>0.823007</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'alph...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7d4e0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>random-forest-classification</td>\n",
       "      <td>0.822848</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'boot...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2a89851da0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>random-forest-classification</td>\n",
       "      <td>0.822689</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'boot...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7df98&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>random-forest-classification</td>\n",
       "      <td>0.822610</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'boot...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7d470&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>random-forest-classification</td>\n",
       "      <td>0.822610</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'boot...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7dac8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>random-forest-classification</td>\n",
       "      <td>0.822055</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'boot...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7dc18&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>random-forest-classification</td>\n",
       "      <td>0.821896</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'boot...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7da90&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>random-forest-classification</td>\n",
       "      <td>0.821817</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'boot...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7db70&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>stochastic-gradient-descent-classification</td>\n",
       "      <td>0.821817</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'alph...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2a89851978&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>basic-neural-network-classification</td>\n",
       "      <td>0.548256</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'acti...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7df60&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>basic-neural-network-classification</td>\n",
       "      <td>0.544357</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'acti...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842d4ca58&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>basic-neural-network-classification</td>\n",
       "      <td>0.544095</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'acti...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842d4cc50&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>basic-neural-network-classification</td>\n",
       "      <td>0.544095</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'acti...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7d518&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>basic-neural-network-classification</td>\n",
       "      <td>0.544057</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'acti...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7de10&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>basic-neural-network-classification</td>\n",
       "      <td>0.542070</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'acti...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7d828&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>basic-neural-network-classification</td>\n",
       "      <td>0.540345</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'acti...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842ba32e8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>basic-neural-network-classification</td>\n",
       "      <td>0.526434</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'acti...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842d4c2e8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>basic-neural-network-classification</td>\n",
       "      <td>0.525122</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'acti...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7def0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>basic-neural-network-classification</td>\n",
       "      <td>0.522197</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'acti...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842d4c9e8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>stochastic-gradient-descent-classification</td>\n",
       "      <td>0.521485</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'alph...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842d4c2b0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>stochastic-gradient-descent-classification</td>\n",
       "      <td>0.517848</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'alph...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842d4c6a0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>basic-neural-network-classification</td>\n",
       "      <td>0.516873</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'acti...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842d4c668&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>stochastic-gradient-descent-classification</td>\n",
       "      <td>0.507012</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'alph...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842ba37b8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>basic-neural-network-classification</td>\n",
       "      <td>0.489576</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'acti...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842d4cb00&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>basic-neural-network-classification</td>\n",
       "      <td>0.480240</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'acti...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7dda0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>stochastic-gradient-descent-classification</td>\n",
       "      <td>0.383390</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'alph...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842d4cdd8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>basic-neural-network-classification</td>\n",
       "      <td>0.339033</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'acti...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7dfd0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>decision-tree-classification</td>\n",
       "      <td>0.336708</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'crit...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842ba3a20&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>decision-tree-classification</td>\n",
       "      <td>0.336708</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'crit...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842ba33c8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>decision-tree-classification</td>\n",
       "      <td>0.336708</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'crit...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842ba3b00&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>decision-tree-classification</td>\n",
       "      <td>0.336708</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'crit...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842ba3518&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>random-forest-classification</td>\n",
       "      <td>0.336708</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'boot...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842ba3630&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>random-forest-classification</td>\n",
       "      <td>0.336708</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'boot...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842d4c828&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>random-forest-classification</td>\n",
       "      <td>0.336708</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'boot...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842d4ca20&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>random-forest-classification</td>\n",
       "      <td>0.336708</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'boot...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842d4c6d8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>random-forest-classification</td>\n",
       "      <td>0.336708</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'boot...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842d4c978&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>decision-tree-classification</td>\n",
       "      <td>0.336708</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'crit...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842ba30f0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>gradient-boosting-classification</td>\n",
       "      <td>0.327489</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'crit...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7d5c0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>gradient-boosting-classification</td>\n",
       "      <td>0.327489</td>\n",
       "      <td>{'_tuning_objective_metric': 'Accuracy', 'crit...</td>\n",
       "      <td>&lt;sagemaker.model.Model object at 0x7f2842e7db00&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Model Name  Metric Results  \\\n",
       "0                          logistic-regression        0.826418   \n",
       "1   stochastic-gradient-descent-classification        0.826418   \n",
       "2                          logistic-regression        0.826339   \n",
       "3                          logistic-regression        0.826339   \n",
       "4                          logistic-regression        0.826339   \n",
       "5                          logistic-regression        0.826339   \n",
       "6                          logistic-regression        0.826339   \n",
       "7          basic-neural-network-classification        0.826259   \n",
       "8                          logistic-regression        0.826259   \n",
       "9                          logistic-regression        0.826101   \n",
       "10                         logistic-regression        0.826101   \n",
       "11                         logistic-regression        0.826021   \n",
       "12  stochastic-gradient-descent-classification        0.826021   \n",
       "13                         logistic-regression        0.826021   \n",
       "14                         logistic-regression        0.825942   \n",
       "15  stochastic-gradient-descent-classification        0.825625   \n",
       "16  stochastic-gradient-descent-classification        0.825625   \n",
       "17         basic-neural-network-classification        0.825228   \n",
       "18                         logistic-regression        0.823562   \n",
       "19                         logistic-regression        0.823403   \n",
       "20         basic-neural-network-classification        0.823007   \n",
       "21  stochastic-gradient-descent-classification        0.823007   \n",
       "22                random-forest-classification        0.822848   \n",
       "23                random-forest-classification        0.822689   \n",
       "24                random-forest-classification        0.822610   \n",
       "25                random-forest-classification        0.822610   \n",
       "26                random-forest-classification        0.822055   \n",
       "27                random-forest-classification        0.821896   \n",
       "28                random-forest-classification        0.821817   \n",
       "29  stochastic-gradient-descent-classification        0.821817   \n",
       "..                                         ...             ...   \n",
       "70         basic-neural-network-classification        0.548256   \n",
       "71         basic-neural-network-classification        0.544357   \n",
       "72         basic-neural-network-classification        0.544095   \n",
       "73         basic-neural-network-classification        0.544095   \n",
       "74         basic-neural-network-classification        0.544057   \n",
       "75         basic-neural-network-classification        0.542070   \n",
       "76         basic-neural-network-classification        0.540345   \n",
       "77         basic-neural-network-classification        0.526434   \n",
       "78         basic-neural-network-classification        0.525122   \n",
       "79         basic-neural-network-classification        0.522197   \n",
       "80  stochastic-gradient-descent-classification        0.521485   \n",
       "81  stochastic-gradient-descent-classification        0.517848   \n",
       "82         basic-neural-network-classification        0.516873   \n",
       "83  stochastic-gradient-descent-classification        0.507012   \n",
       "84         basic-neural-network-classification        0.489576   \n",
       "85         basic-neural-network-classification        0.480240   \n",
       "86  stochastic-gradient-descent-classification        0.383390   \n",
       "87         basic-neural-network-classification        0.339033   \n",
       "88                decision-tree-classification        0.336708   \n",
       "89                decision-tree-classification        0.336708   \n",
       "90                decision-tree-classification        0.336708   \n",
       "91                decision-tree-classification        0.336708   \n",
       "92                random-forest-classification        0.336708   \n",
       "93                random-forest-classification        0.336708   \n",
       "94                random-forest-classification        0.336708   \n",
       "95                random-forest-classification        0.336708   \n",
       "96                random-forest-classification        0.336708   \n",
       "97                decision-tree-classification        0.336708   \n",
       "98            gradient-boosting-classification        0.327489   \n",
       "99            gradient-boosting-classification        0.327489   \n",
       "\n",
       "                                      HyperParameters  \\\n",
       "0   {'C': '0.865280262065544', '_tuning_objective_...   \n",
       "1   {'_tuning_objective_metric': 'Accuracy', 'alph...   \n",
       "2   {'C': '0.9995955195233935', '_tuning_objective...   \n",
       "3   {'C': '1.0', '_tuning_objective_metric': 'Accu...   \n",
       "4   {'C': '0.8778731048356974', '_tuning_objective...   \n",
       "5   {'C': '0.8682699554216349', '_tuning_objective...   \n",
       "6   {'C': '0.9199331634294474', '_tuning_objective...   \n",
       "7   {'_tuning_objective_metric': 'Accuracy', 'acti...   \n",
       "8   {'C': '0.9105947845231974', '_tuning_objective...   \n",
       "9   {'C': '0.9741506927263224', '_tuning_objective...   \n",
       "10  {'C': '0.9782705657731974', '_tuning_objective...   \n",
       "11  {'C': '0.9370169036638224', '_tuning_objective...   \n",
       "12  {'_tuning_objective_metric': 'Accuracy', 'alph...   \n",
       "13  {'C': '0.9427297942888224', '_tuning_objective...   \n",
       "14  {'C': '0.7242842376481974', '_tuning_objective...   \n",
       "15  {'_tuning_objective_metric': 'Accuracy', 'alph...   \n",
       "16  {'_tuning_objective_metric': 'Accuracy', 'alph...   \n",
       "17  {'_tuning_objective_metric': 'Accuracy', 'acti...   \n",
       "18  {'C': '0.36073785092944743', '_tuning_objectiv...   \n",
       "19  {'C': '0.31521819760913494', '_tuning_objectiv...   \n",
       "20  {'_tuning_objective_metric': 'Accuracy', 'acti...   \n",
       "21  {'_tuning_objective_metric': 'Accuracy', 'alph...   \n",
       "22  {'_tuning_objective_metric': 'Accuracy', 'boot...   \n",
       "23  {'_tuning_objective_metric': 'Accuracy', 'boot...   \n",
       "24  {'_tuning_objective_metric': 'Accuracy', 'boot...   \n",
       "25  {'_tuning_objective_metric': 'Accuracy', 'boot...   \n",
       "26  {'_tuning_objective_metric': 'Accuracy', 'boot...   \n",
       "27  {'_tuning_objective_metric': 'Accuracy', 'boot...   \n",
       "28  {'_tuning_objective_metric': 'Accuracy', 'boot...   \n",
       "29  {'_tuning_objective_metric': 'Accuracy', 'alph...   \n",
       "..                                                ...   \n",
       "70  {'_tuning_objective_metric': 'Accuracy', 'acti...   \n",
       "71  {'_tuning_objective_metric': 'Accuracy', 'acti...   \n",
       "72  {'_tuning_objective_metric': 'Accuracy', 'acti...   \n",
       "73  {'_tuning_objective_metric': 'Accuracy', 'acti...   \n",
       "74  {'_tuning_objective_metric': 'Accuracy', 'acti...   \n",
       "75  {'_tuning_objective_metric': 'Accuracy', 'acti...   \n",
       "76  {'_tuning_objective_metric': 'Accuracy', 'acti...   \n",
       "77  {'_tuning_objective_metric': 'Accuracy', 'acti...   \n",
       "78  {'_tuning_objective_metric': 'Accuracy', 'acti...   \n",
       "79  {'_tuning_objective_metric': 'Accuracy', 'acti...   \n",
       "80  {'_tuning_objective_metric': 'Accuracy', 'alph...   \n",
       "81  {'_tuning_objective_metric': 'Accuracy', 'alph...   \n",
       "82  {'_tuning_objective_metric': 'Accuracy', 'acti...   \n",
       "83  {'_tuning_objective_metric': 'Accuracy', 'alph...   \n",
       "84  {'_tuning_objective_metric': 'Accuracy', 'acti...   \n",
       "85  {'_tuning_objective_metric': 'Accuracy', 'acti...   \n",
       "86  {'_tuning_objective_metric': 'Accuracy', 'alph...   \n",
       "87  {'_tuning_objective_metric': 'Accuracy', 'acti...   \n",
       "88  {'_tuning_objective_metric': 'Accuracy', 'crit...   \n",
       "89  {'_tuning_objective_metric': 'Accuracy', 'crit...   \n",
       "90  {'_tuning_objective_metric': 'Accuracy', 'crit...   \n",
       "91  {'_tuning_objective_metric': 'Accuracy', 'crit...   \n",
       "92  {'_tuning_objective_metric': 'Accuracy', 'boot...   \n",
       "93  {'_tuning_objective_metric': 'Accuracy', 'boot...   \n",
       "94  {'_tuning_objective_metric': 'Accuracy', 'boot...   \n",
       "95  {'_tuning_objective_metric': 'Accuracy', 'boot...   \n",
       "96  {'_tuning_objective_metric': 'Accuracy', 'boot...   \n",
       "97  {'_tuning_objective_metric': 'Accuracy', 'crit...   \n",
       "98  {'_tuning_objective_metric': 'Accuracy', 'crit...   \n",
       "99  {'_tuning_objective_metric': 'Accuracy', 'crit...   \n",
       "\n",
       "                                        Actual Model  \n",
       "0   <sagemaker.model.Model object at 0x7f2a89ec75c0>  \n",
       "1   <sagemaker.model.Model object at 0x7f2842e7dd68>  \n",
       "2   <sagemaker.model.Model object at 0x7f2842e7d048>  \n",
       "3   <sagemaker.model.Model object at 0x7f2a8a488908>  \n",
       "4   <sagemaker.model.Model object at 0x7f2a8a488e10>  \n",
       "5   <sagemaker.model.Model object at 0x7f2842e7d978>  \n",
       "6   <sagemaker.model.Model object at 0x7f2a89ec7320>  \n",
       "7   <sagemaker.model.Model object at 0x7f2a89851cf8>  \n",
       "8   <sagemaker.model.Model object at 0x7f2842e7d630>  \n",
       "9   <sagemaker.model.Model object at 0x7f2a8a488748>  \n",
       "10  <sagemaker.model.Model object at 0x7f2a8a4887f0>  \n",
       "11  <sagemaker.model.Model object at 0x7f2a89ec7a90>  \n",
       "12  <sagemaker.model.Model object at 0x7f2842e7deb8>  \n",
       "13  <sagemaker.model.Model object at 0x7f2a8a4884a8>  \n",
       "14  <sagemaker.model.Model object at 0x7f2a8a4883c8>  \n",
       "15  <sagemaker.model.Model object at 0x7f2842e7de80>  \n",
       "16  <sagemaker.model.Model object at 0x7f2842e7d860>  \n",
       "17  <sagemaker.model.Model object at 0x7f2a89851e48>  \n",
       "18  <sagemaker.model.Model object at 0x7f2842e7d5f8>  \n",
       "19  <sagemaker.model.Model object at 0x7f2a8a488470>  \n",
       "20  <sagemaker.model.Model object at 0x7f2a8a488c50>  \n",
       "21  <sagemaker.model.Model object at 0x7f2842e7d4e0>  \n",
       "22  <sagemaker.model.Model object at 0x7f2a89851da0>  \n",
       "23  <sagemaker.model.Model object at 0x7f2842e7df98>  \n",
       "24  <sagemaker.model.Model object at 0x7f2842e7d470>  \n",
       "25  <sagemaker.model.Model object at 0x7f2842e7dac8>  \n",
       "26  <sagemaker.model.Model object at 0x7f2842e7dc18>  \n",
       "27  <sagemaker.model.Model object at 0x7f2842e7da90>  \n",
       "28  <sagemaker.model.Model object at 0x7f2842e7db70>  \n",
       "29  <sagemaker.model.Model object at 0x7f2a89851978>  \n",
       "..                                               ...  \n",
       "70  <sagemaker.model.Model object at 0x7f2842e7df60>  \n",
       "71  <sagemaker.model.Model object at 0x7f2842d4ca58>  \n",
       "72  <sagemaker.model.Model object at 0x7f2842d4cc50>  \n",
       "73  <sagemaker.model.Model object at 0x7f2842e7d518>  \n",
       "74  <sagemaker.model.Model object at 0x7f2842e7de10>  \n",
       "75  <sagemaker.model.Model object at 0x7f2842e7d828>  \n",
       "76  <sagemaker.model.Model object at 0x7f2842ba32e8>  \n",
       "77  <sagemaker.model.Model object at 0x7f2842d4c2e8>  \n",
       "78  <sagemaker.model.Model object at 0x7f2842e7def0>  \n",
       "79  <sagemaker.model.Model object at 0x7f2842d4c9e8>  \n",
       "80  <sagemaker.model.Model object at 0x7f2842d4c2b0>  \n",
       "81  <sagemaker.model.Model object at 0x7f2842d4c6a0>  \n",
       "82  <sagemaker.model.Model object at 0x7f2842d4c668>  \n",
       "83  <sagemaker.model.Model object at 0x7f2842ba37b8>  \n",
       "84  <sagemaker.model.Model object at 0x7f2842d4cb00>  \n",
       "85  <sagemaker.model.Model object at 0x7f2842e7dda0>  \n",
       "86  <sagemaker.model.Model object at 0x7f2842d4cdd8>  \n",
       "87  <sagemaker.model.Model object at 0x7f2842e7dfd0>  \n",
       "88  <sagemaker.model.Model object at 0x7f2842ba3a20>  \n",
       "89  <sagemaker.model.Model object at 0x7f2842ba33c8>  \n",
       "90  <sagemaker.model.Model object at 0x7f2842ba3b00>  \n",
       "91  <sagemaker.model.Model object at 0x7f2842ba3518>  \n",
       "92  <sagemaker.model.Model object at 0x7f2842ba3630>  \n",
       "93  <sagemaker.model.Model object at 0x7f2842d4c828>  \n",
       "94  <sagemaker.model.Model object at 0x7f2842d4ca20>  \n",
       "95  <sagemaker.model.Model object at 0x7f2842d4c6d8>  \n",
       "96  <sagemaker.model.Model object at 0x7f2842d4c978>  \n",
       "97  <sagemaker.model.Model object at 0x7f2842ba30f0>  \n",
       "98  <sagemaker.model.Model object at 0x7f2842e7d5c0>  \n",
       "99  <sagemaker.model.Model object at 0x7f2842e7db00>  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at the model results\n",
    "modeling_df = pd.DataFrame({'Model Name': images,\n",
    "                            'Metric Results': scores,\n",
    "                            'HyperParameters': hypers,\n",
    "                            'Actual Model': models})\n",
    "modeling_df = modeling_df.sort_values('Metric Results', ascending=False)\n",
    "modeling_df = modeling_df.reset_index(drop=True)\n",
    "modeling_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic-regression:\n",
      "{'C': '0.865280262065544', '_tuning_objective_metric': 'Accuracy', 'data_type': 'text', 'multi_class': 'multinomial', 'solver': 'newton-cg'}\n",
      "stochastic-gradient-descent-classification:\n",
      "{'_tuning_objective_metric': 'Accuracy', 'alpha': '0.0036573825316065425', 'data_type': 'word', 'eta0': '0.046752434891641693', 'l1_ratio': '0.4414895769855142', 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'none', 'power_t': '0.3536959988101933'}\n",
      "logistic-regression:\n",
      "{'C': '0.9995955195233935', '_tuning_objective_metric': 'Accuracy', 'data_type': 'word', 'multi_class': 'auto', 'solver': 'sag'}\n"
     ]
    }
   ],
   "source": [
    "#show hyper params for best text models\n",
    "how_many_models_to_test = 3\n",
    "for row_num in range(0,how_many_models_to_test):\n",
    "    print(modeling_df.loc[row_num, 'Model Name'] + ':\\n' + str(modeling_df.loc[row_num, 'HyperParameters']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_hyper = {'C': '0.865280262065544', \n",
    "               'multi_class': 'multinomial', \n",
    "               'solver': 'newton-cg'}\n",
    "sgd_hyper = {'alpha': '0.0036573825316065425', \n",
    "               'eta0': '0.046752434891641693',\n",
    "               'l1_ratio': '0.4414895769855142',\n",
    "               'learning_rate': 'adaptive',\n",
    "               'loss': 'log',\n",
    "               'penalty': 'none',\n",
    "               'power_t': '0.3536959988101933'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the logit\n",
    "logit = LogisticRegression(C=float(logit_hyper['C']),\n",
    "                            solver=logit_hyper['solver'],\n",
    "                            max_iter=10000,\n",
    "                            multi_class=logit_hyper['multi_class'])\n",
    "\n",
    "logit = logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#train sgd\n",
    "sgd = SGDClassifier(loss=sgd_hyper['loss'],\n",
    "                        penalty=sgd_hyper['penalty'],\n",
    "                        alpha=float(sgd_hyper['alpha']),\n",
    "                        l1_ratio=float(sgd_hyper['l1_ratio']),\n",
    "                        max_iter=10000,\n",
    "                        learning_rate=sgd_hyper['learning_rate'],\n",
    "                        eta0=float(sgd_hyper['eta0']),\n",
    "                        power_t=float(sgd_hyper['power_t']))    \n",
    "\n",
    "\n",
    "sgd = sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Model.\n",
      "Model Results\n",
      "[[4011  311   35   26  214   11    0   28]\n",
      " [ 226 4118   45   25  195    1    0   12]\n",
      " [ 115  128  728   16   15    1    0   12]\n",
      " [  80   53   27  934  152    6    0    0]\n",
      " [ 292  236   14   31 1233    2    0    5]\n",
      " [  39   22    5    6   14   25    0    3]\n",
      " [   0    0    0    0    0    0   18    1]\n",
      " [  33   28    8    0    3    0    0  462]]\n",
      "Accuracy: 0.8232059978579079\n",
      "Recall: 0.8232059978579079\n",
      "Precision: 0.8229488327335591\n",
      "F1-Score: 0.8211746065116802\n"
     ]
    }
   ],
   "source": [
    "print('Testing Model.')\n",
    "y_pred_logit = logit.predict(X_test)\n",
    "\n",
    "#model results\n",
    "print('Model Results')\n",
    "print(confusion_matrix(y_test, y_pred_logit))\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred_logit)))\n",
    "print('Recall: ' + str(recall_score(y_test, y_pred_logit, average='weighted')))\n",
    "print('Precision: ' + str(precision_score(y_test, y_pred_logit, average='weighted')))\n",
    "print('F1-Score: ' + str(f1_score(y_test, y_pred_logit, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Model.\n",
      "Model Results\n",
      "[[3703  375  106   81  309   29    0   33]\n",
      " [ 362 3807   85   55  288    9    0   16]\n",
      " [ 119  111  706   31   31    8    1    8]\n",
      " [  88   78   37  929  117    3    0    0]\n",
      " [ 294  297   34   67 1091   17    0   13]\n",
      " [  38   12    8   12    9   33    0    2]\n",
      " [   1    0    0    0    0    0   17    1]\n",
      " [  29   29   10    1    3    4    0  458]]\n",
      "Accuracy: 0.7671545876472688\n",
      "Recall: 0.7671545876472688\n",
      "Precision: 0.7670445127403522\n",
      "F1-Score: 0.7669836866347125\n"
     ]
    }
   ],
   "source": [
    "print('Testing Model.')\n",
    "y_pred_sgd = sgd.predict(X_test)\n",
    "\n",
    "#model results\n",
    "print('Model Results')\n",
    "print(confusion_matrix(y_test, y_pred_sgd))\n",
    "print('Accuracy: ' + str(accuracy_score(y_test, y_pred_sgd)))\n",
    "print('Recall: ' + str(recall_score(y_test, y_pred_sgd, average='weighted')))\n",
    "print('Precision: ' + str(precision_score(y_test, y_pred_sgd, average='weighted')))\n",
    "print('F1-Score: ' + str(f1_score(y_test, y_pred_sgd, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#safe off best model\n",
    "pickle.dump(logit, open('text-model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknowns = count_vectorizer.transform(all_unknowns['Mobile Data Remarks'])\n",
    "unknown_pred = logit.predict(unknowns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25 ALF BLOWN AT PT 72 5159 UNKNOWN CAUSE BACK...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8 ATF BLOWN AT PT 73 263 UNKNOWN CAUSE REPLAC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8 AMP TRANS FUSE WAS BLOWN UNKNOWN CAUSE AT P...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CLOSED RISER FUSE REPLACED FUSE</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CLOSED 12K LINE FUSE ON POLE 71 2346 TIME WAS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  predictions\n",
       "0   25 ALF BLOWN AT PT 72 5159 UNKNOWN CAUSE BACK...            0\n",
       "1   8 ATF BLOWN AT PT 73 263 UNKNOWN CAUSE REPLAC...            0\n",
       "2   8 AMP TRANS FUSE WAS BLOWN UNKNOWN CAUSE AT P...            0\n",
       "3                   CLOSED RISER FUSE REPLACED FUSE             4\n",
       "4   CLOSED 12K LINE FUSE ON POLE 71 2346 TIME WAS...            1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_pred_df = pd.DataFrame({'comments': all_unknowns['Mobile Data Remarks'].reset_index(drop=True),\n",
    "                                   'predictions': pd.Series(data=unknown_pred)})\n",
    "unknown_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Word': {0: 'Equipment',\n",
       "  1: 'Vegetation',\n",
       "  2: 'Public',\n",
       "  3: 'Wildlife',\n",
       "  4: 'Weather',\n",
       "  5: 'Other',\n",
       "  6: 'Power Supply',\n",
       "  7: 'Planned'},\n",
       " 'Number': {0: 0, 1: 7, 2: 5, 3: 9, 4: 8, 5: 2, 6: 4, 7: 3}}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_dict = decoder.to_dict()\n",
    "decoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>predictions</th>\n",
       "      <th>outage_category_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25 ALF BLOWN AT PT 72 5159 UNKNOWN CAUSE BACK...</td>\n",
       "      <td>0</td>\n",
       "      <td>Equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8 ATF BLOWN AT PT 73 263 UNKNOWN CAUSE REPLAC...</td>\n",
       "      <td>0</td>\n",
       "      <td>Equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8 AMP TRANS FUSE WAS BLOWN UNKNOWN CAUSE AT P...</td>\n",
       "      <td>0</td>\n",
       "      <td>Equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CLOSED RISER FUSE REPLACED FUSE</td>\n",
       "      <td>4</td>\n",
       "      <td>Weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CLOSED 12K LINE FUSE ON POLE 71 2346 TIME WAS...</td>\n",
       "      <td>1</td>\n",
       "      <td>Vegetation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  predictions  \\\n",
       "0   25 ALF BLOWN AT PT 72 5159 UNKNOWN CAUSE BACK...            0   \n",
       "1   8 ATF BLOWN AT PT 73 263 UNKNOWN CAUSE REPLAC...            0   \n",
       "2   8 AMP TRANS FUSE WAS BLOWN UNKNOWN CAUSE AT P...            0   \n",
       "3                   CLOSED RISER FUSE REPLACED FUSE             4   \n",
       "4   CLOSED 12K LINE FUSE ON POLE 71 2346 TIME WAS...            1   \n",
       "\n",
       "  outage_category_pred  \n",
       "0            Equipment  \n",
       "1            Equipment  \n",
       "2            Equipment  \n",
       "3              Weather  \n",
       "4           Vegetation  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def category_name(data):\n",
    "    \n",
    "    return decoder_dict['Word'][data]\n",
    "\n",
    "unknown_pred_df['outage_category_pred'] = unknown_pred_df['predictions'].apply(category_name)\n",
    "unknown_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_pred_df.to_csv('Unknown Outage Category Predictions.csv', index=False)\n",
    "\n",
    "output_path = sess.upload_data(\n",
    "    path='Unknown Outage Category Predictions.csv', bucket=bucket,\n",
    "    key_prefix='sagemaker/results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_words = pd.DataFrame({'Equipment': logit.coef_[0],\n",
    "                          'Vegetation': logit.coef_[1],\n",
    "                           'Public': logit.coef_[2],\n",
    "                           'Wildlife': logit.coef_[3],\n",
    "                           'Weather': logit.coef_[4],\n",
    "                           'Other': logit.coef_[5],\n",
    "                           'Power Supply': logit.coef_[6],\n",
    "                           'Planned': logit.coef_[7]},\n",
    "                         index=count_vectorizer.get_feature_names())\n",
    "\n",
    "best_words.to_csv('Best Words.csv')\n",
    "\n",
    "output_path = sess.upload_data(\n",
    "    path='Best Words.csv', bucket=bucket,\n",
    "    key_prefix='sagemaker/results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: Stochastic-Gradient--191016-1544-003-625076be\n"
     ]
    }
   ],
   "source": [
    "def run_batch_transform(model, test_data_location):\n",
    "    '''\n",
    "    Test the data by running the test data through batch transform job.\n",
    "    '''\n",
    "\n",
    "    transformer = model.transformer(instance_count=1,\n",
    "                                    instance_type='ml.c5.4xlarge',\n",
    "                                    output_path='s3://{}/batch_results/{}'.format(bucket, model.name)\n",
    "                                   )\n",
    "\n",
    "    transformer.transform(data=test_data_location, content_type='text/csv')\n",
    "\n",
    "\n",
    "how_many_models_to_test = 1\n",
    "for model in modeling_df['Actual Model'][:how_many_models_to_test]:\n",
    "    run_batch_transform(model, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy batch transform data to local instance\n",
    "os.system('aws s3 sync s3://{}/batch_results/ /home/ec2-user/SageMaker/AmazonSageMaker-we-energies-customer-retention/batch_results/'.format(bucket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe():\n",
    "    '''\n",
    "    Loops through the directory on your local notebook instance where the batch results were stored, \n",
    "        and generates a dataframe where each column is the output from a different model.\n",
    "    '''\n",
    "    frames  = []\n",
    "    \n",
    "    for sub_dir in os.listdir('/home/ec2-user/SageMaker/AmazonSageMaker-we-energies-customer-retention/batch_results'):\n",
    "        if '.ipynb' not in sub_dir and '.out' not in sub_dir:\n",
    "\n",
    "            old_file = '/home/ec2-user/SageMaker/AmazonSageMaker-we-energies-customer-retention/batch_results/{}/test_data_180.csv.out'.format(sub_dir)\n",
    "            \n",
    "            new_file = '/home/ec2-user/SageMaker/AmazonSageMaker-we-energies-customer-retention/batch_results/{}/test_data_180.csv'.format(sub_dir)\n",
    "            \n",
    "            # remove the .out file formate\n",
    "            os.system('cp {} {}'.format( old_file, new_file))\n",
    "            \n",
    "            df = pd.read_csv('/home/ec2-user/SageMaker/AmazonSageMaker-we-energies-customer-retention/batch_results/{}/test_data_180.csv'.format(sub_dir), names = [sub_dir])\n",
    "\n",
    "            frames.append(df)\n",
    "            \n",
    "    df = pd.concat(frames, axis=1)\n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_results(df):\n",
    "    '''\n",
    "    find range of predictions\n",
    "    '''\n",
    "\n",
    "    df['max'] = 0\n",
    "    df['min'] = 0\n",
    "    df['diff'] = 0\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "        top = max(row)\n",
    "        bottom = min(row)\n",
    "\n",
    "        diff = top - bottom\n",
    "\n",
    "        df.loc[idx, 'max'] = top\n",
    "        df.loc[idx, 'min'] = bottom\n",
    "        df.loc[idx, 'diff'] = diff\n",
    "\n",
    "    return df\n",
    "\n",
    "bare_df = get_dataframe()\n",
    "consolidated_df = consolidate_results(bare_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label_to_results(df):\n",
    "    '''\n",
    "    add the true outcomes to the dataframe\n",
    "    '''\n",
    "    #test_data = pd.read_csv('test_data_180.csv')\n",
    "    y_true = test_data['close_in_180'].values.tolist()\n",
    "    df['y_true'] = y_true\n",
    "    return df\n",
    "    \n",
    "    \n",
    "testing_df = add_label_to_results(consolidated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(df, model_column, accuracy=None):\n",
    "    '''\n",
    "    create a confusion matrix.\n",
    "    '''\n",
    "    \n",
    "    mx = pd.crosstab(index=df['y_true'], columns=np.round(df[model_column]), rownames=['actuals'], colnames=['predictions'])\n",
    "\n",
    "    # lower right corner\n",
    "    tps = mx.iloc[1, 1]\n",
    "        \n",
    "    # upper right corner\n",
    "    fps = mx.iloc[0, 1]\n",
    "    \n",
    "    # lower left corner\n",
    "    fns = mx.iloc[1, 0]\n",
    "    \n",
    "    precision = np.round(tps / (tps + fns), 4) * 100\n",
    "    \n",
    "    recall = np.round(tps / (tps + fps), 4) * 100\n",
    "    \n",
    "    print ('Precision = {}%, Recall = {}%'.format(precision, recall))\n",
    "    \n",
    "    if accuracy:\n",
    "        \n",
    "        # upper left corner \n",
    "        tns = mx.iloc[0, 0]\n",
    "        \n",
    "        accuracy = (tps + tns) / (fns + fps + tps + tns) * 100\n",
    "        \n",
    "        print ('Overall binary classification accuracy = {}%'.format(accuracy))\n",
    "        \n",
    "    return mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get model results\n",
    "get_confusion_matrix(testing_df,'Random-Forest-Classi-191009-1813-006-ec402e88', accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enssembling?\n",
    "get_confusion_matrix(testing_df, 'max', accuracy=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
