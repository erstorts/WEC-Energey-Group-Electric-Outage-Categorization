{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outage category</th>\n",
       "      <th>outage subcategory</th>\n",
       "      <th>Mobile Data Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Conductor/Cable</td>\n",
       "      <td>one leg of urd is dead customer said we can f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Out Clearance Zone (ROW)</td>\n",
       "      <td>removed tree from line nearpole63 1688 and cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Conductor/Cable</td>\n",
       "      <td>repaired bad primary urd cables cable repaire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bad connector on cust serv pole conn replaced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Simple Interrupting Device</td>\n",
       "      <td>replaced broken cutout and installed wlp taq ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outage category          outage subcategory  \\\n",
       "0                0             Conductor/Cable   \n",
       "1                1    Out Clearance Zone (ROW)   \n",
       "2                0             Conductor/Cable   \n",
       "3                0                         NaN   \n",
       "4                0  Simple Interrupting Device   \n",
       "\n",
       "                                 Mobile Data Remarks  \n",
       "0   one leg of urd is dead customer said we can f...  \n",
       "1   removed tree from line nearpole63 1688 and cl...  \n",
       "2   repaired bad primary urd cables cable repaire...  \n",
       "3   bad connector on cust serv pole conn replaced...  \n",
       "4   replaced broken cutout and installed wlp taq ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import text data\n",
    "outage = pd.read_csv('We_WPS_comments_categories.csv')\n",
    "\n",
    "#seperating out unknown causes\n",
    "all_unknowns = outage[outage['outage category'] == 'Unknown']\n",
    "#save off unknowns\n",
    "#all_unknowns.to_csv('Unknown Outcomes.csv')\n",
    "#remove unknowns and not reporteable\n",
    "outage = outage[outage['outage category'] != 'Unknown']\n",
    "outage = outage[outage['outage category'] != 'Not Reportable']\n",
    "\n",
    "#convert target to numeric\n",
    "outage['outage category'] = pd.factorize(outage['outage category'])[0]\n",
    "outage = outage[outage['Mobile Data Remarks'].notna()]\n",
    "outage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(outage, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizing(vectorizing_type):\n",
    "    if vectorizing_type == 'Count':\n",
    "        return CountVectorizer(stop_words='english')\n",
    "    elif vectorizing_type == 'TFIDF':\n",
    "        return TfidfVectorizer(stop_words='english')\n",
    "    elif vectorizing_type == 'Hash':\n",
    "        return HashingVectorizer(stop_words='english')\n",
    "    else:\n",
    "        return print('Vectorizer Not an option')\n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_model(algorithm_name, components):\n",
    "    if algorithm_name == 'NMF':\n",
    "        model = NMF(n_components=components)\n",
    "        \n",
    "    elif algorithm_name == 'SVD':\n",
    "        model = TruncatedSVD(n_components=components)\n",
    "        \n",
    "    else:\n",
    "        print('Algorithnm is not an option.')\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_model(training_data, testing_data):\n",
    "    \n",
    "    logit_hyper = {'C': '0.865280262065544', \n",
    "                   'multi_class': 'multinomial', \n",
    "                   'solver': 'newton-cg'}\n",
    "    \n",
    "    #train the logit\n",
    "    logit = LogisticRegression(C=float(logit_hyper['C']),\n",
    "                                solver=logit_hyper['solver'],\n",
    "                                max_iter=10000,\n",
    "                                multi_class=logit_hyper['multi_class'])\n",
    "\n",
    "    logit = logit.fit(training_data, train_data['outage category'])\n",
    "\n",
    "    y_pred_logit = logit.predict(testing_data)\n",
    "    return accuracy_score(test_data['outage category'], y_pred_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_time = []\n",
    "unsupervised_train_time = []\n",
    "unsupervised_apply_time = []\n",
    "model_time = []\n",
    "model_accuracy = []\n",
    "this_vector = []\n",
    "this_algorithm = []\n",
    "this_component = []\n",
    "\n",
    "\n",
    "vectorizing_types = ['Count', #'TFIDF', 'Hash'\n",
    "                    ]\n",
    "algorithm_names = [#'NMF', \n",
    "                    'SVD'\n",
    "                    #'None'\n",
    "                    ]\n",
    "components = [25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "Vectorizing\n",
      "Unsupervised\n"
     ]
    }
   ],
   "source": [
    "for vectorizing_type in vectorizing_types:\n",
    "    for algorithm_name in algorithm_names:\n",
    "        for component in components:\n",
    "            print('Start')\n",
    "            start = datetime.datetime.now()\n",
    "\n",
    "            print('Vectorizing')\n",
    "            #vector\n",
    "            this_vector.append(vectorizing_type)\n",
    "            vectorizer = vectorizing(vectorizing_type)\n",
    "            X_train = vectorizer.fit_transform(train_data['Mobile Data Remarks'])\n",
    "            X_test = vectorizer.transform(test_data['Mobile Data Remarks'])\n",
    "\n",
    "            vector_times_actual = datetime.datetime.now()\n",
    "            vector_time.append(vector_times_actual - start)\n",
    "\n",
    "            \n",
    "            if vectorizing_type == 'Hash' and algorithm_name == 'NMF':\n",
    "                print('Current Match Will not Work.\\n')\n",
    "                this_algorithm.append(algorithm_name)\n",
    "                this_component.append(0)\n",
    "                unsupervised_train_time.append(0)\n",
    "                unsupervised_apply_time.append(0)\n",
    "                model_accuracy.append(0)\n",
    "                model_time.append(0)\n",
    "            else:\n",
    "                if algorithm_name == 'None':\n",
    "                    print('No Unsupervised')\n",
    "                    this_algorithm.append(algorithm_name)\n",
    "                    this_component.append(component)\n",
    "                    unsupervised_train_time.append(0)\n",
    "                    unsupervised_apply_time.append(0)\n",
    "                    \n",
    "                    print('Logit')\n",
    "                    #logit model\n",
    "                    model_accuracy.append(logit_model(X_train, X_test))\n",
    "                    modeling_time = datetime.datetime.now()\n",
    "                    model_time.append(modeling_time - apply_time)\n",
    "                    \n",
    "                else:\n",
    "                    print('Unsupervised')\n",
    "                    #unsupervied modeling\n",
    "                    this_algorithm.append(algorithm_name)\n",
    "                    this_component.append(component)\n",
    "                    model = unsupervised_model(algorithm_name, component)\n",
    "                    model.fit(X_train)\n",
    "                    train_time = datetime.datetime.now()\n",
    "                    unsupervised_train_time.append(train_time - vector_times_actual)\n",
    "\n",
    "                    new_X_train = model.transform(X_train)\n",
    "                    new_X_test = model.transform(X_test)\n",
    "                    apply_time = datetime.datetime.now()\n",
    "                    unsupervised_apply_time.append(apply_time - train_time)\n",
    "                    \n",
    "                    print('Logit')\n",
    "                    #logit model\n",
    "                    model_accuracy.append(logit_model(new_X_train, new_X_test))\n",
    "                    modeling_time = datetime.datetime.now()\n",
    "                    model_time.append(modeling_time - apply_time)\n",
    "\n",
    "                    print('Done.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({'Vector': this_vector,\n",
    "                           'Vector Time': vector_time,\n",
    "                           'Unsupervised Algorithm': this_algorithm,\n",
    "                           'HyperTune Parameter': this_component,\n",
    "                           'Unsupervised Train Time': unsupervised_train_time,\n",
    "                           'Unsupervised Apply Time': unsupervised_apply_time,\n",
    "                           'Model Time': model_time,\n",
    "                           'Model Accuracy': model_accuracy\n",
    "                          })\n",
    "                           \n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count SVD 20000 50min 55min 27min 0.818657\n",
    "# Count None                  28min 0.822734"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
